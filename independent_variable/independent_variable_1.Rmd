---
title: "Select independent variable"
output: html_document
date: "2025-04-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Đọc dữ liệu đã làm sạch

```{r}
library(glmnet) 
library(lmtest)
library(MASS)
library(caret)
library(knitr)
library(broom)
library(knitr)
library(dplyr)
library(ggcorrplot)     # Vẽ ma trận tương quan
library(ggplot2)
library(car)            # Tính VIF
library(corrplot)       # Vẽ biểu đồ tương quan
data_cleaned <- read.csv("../data_set/data_cleaned.csv")
```

# chọn biến dựa trên cơ sở lý thuyết trước đó (đọc và nghiên cứu file csv hoặc tìm hiểu các nghiên cứu tương tự) đi đến chọn biến và đem đi kiểm định bằng phương pháp sử dụng ma trận tương quan để kiểm tra

>>> Toàn
# Phân chia dữ liệu: 70% train - 30% test

```{r}
train_index <- createDataPartition(data_cleaned$LIFE.EXPECTANCY, p = 0.7, list = FALSE)
train_data <- data_cleaned[train_index, ]
test_data <- data_cleaned[-train_index, ]
```

```{r}
# Lựa chọn các biến có tương quan tốt và không đa cộng tuyến cao
selected_data <- train_data %>%
  select(LIFE.EXPECTANCY, INCOME.COMPOSITION.OF.RESOURCES, ADULT.MORTALITY, BMI,PERCENTAGE.EXPENDITURE,TOTAL.EXPENDITURE, SCHOOLING)
```

```{r}
#Tính và vẽ ma trận tương quan
cor_matrix <- cor(selected_data, use = "complete.obs")

ggcorrplot(
  cor_matrix,
  hc.order = FALSE,  # Tắt sắp xếp phân cụm để giữ nguyên thứ tự biến
  type = "full",     # Hiển thị toàn bộ ma trận (không chỉ nửa dưới)
  lab = TRUE,
  lab_size = 3,
  tl.cex = 8,        # Tăng kích thước chữ tên biến
  tl.srt = 45,       # Xoay tên biến 45 độ
  title = "Ma trận tương quan giữa các biến",
) +
  theme(
    axis.text.x = element_text(size = 8, angle = 45, hjust = 1),
    axis.text.y = element_text(size = 8)
  )
```

>> (THEO Ý CỦA TOÀN)

Từ ma trận tương quan ta chọn các biến có |r| > 0.3 so với biến LIFE.EXPECTANCY
Mục đích: Loại bỏ các biến ngẫu nhiên, ít ảnh hưởng đến tuổi thọ
--> Chọn được các biến để xây dựng mô hình: INCOME.COMPOSITION.OF.RESOURCES, ADULT.MORTALITY,
BMI, SCHOOLING


# \>\>\>\>\> XÂY DỰNG CÁC MÔ HÌNH \<\<\<\<\<

#KIỂM TRA ĐA CỘNG TUYẾN

```{r}
initial_model <- lm(LIFE.EXPECTANCY ~ INCOME.COMPOSITION.OF.RESOURCES + 
                     ADULT.MORTALITY + SCHOOLING + BMI, 
                   data = train_data)
vif(initial_model)
```
Nhận xét: Nhìn chung các biến đều không đa cộng tuyến cao, nhưng cần chú ý ở 2 biến là INCOME.COMPOSITION.OF.RESOURCES và SCHOOLING, hai biến này có mức độ cộng tuyến ở mức trung bình. Từ đó có thể bị ảnh hưởng bởi các biến khác trong mô hình -> gây ảnh hưởng đến tính ổn định của ước lượng hệ số hồi quy
Tuy không quá nghiêm trọng, nhưng cũng cần xử lý, chúng ta có thể kết hợp hai biến INCOME.COMPOSITION.OF.RESOURCES và  SCHOOLING để thành 1 biến tổng hợp, hoặc sử dụng thêm model để có thể làm giảm mức ảnh hường đa cộng tuyến và đem so sánh với model ban đầu để đưa ra được kết quả tốt nhất. -> 

----------------------------------------------------------------------------------------------------------------
## Mô hình ban đầu

```{r}
model <- lm(LIFE.EXPECTANCY ~ INCOME.COMPOSITION.OF.RESOURCES + 
              ADULT.MORTALITY + SCHOOLING + BMI, 
            data = train_data)

```

## Stepwise Regression (AIC) để chọn biến

```{r}
final_model <- stepAIC(model, direction = "both", trace = FALSE)
summary(final_model)
```
## Sự khác biệt giữa mô hình ban đầu và mô hình sử dụng AIC (lọc các biến không cần thiết tự động)

```{r}
formula(model)  # Xem mô hình ban đầu
formula(final_model)  # Xem mô hình sau khi tối ưu
```
>>>Nhìn vào kết quả cho thấy được mô hình ban đầu và mô hình sau khi áp dụng AIC thì các biến vẫn giữu nguyên, điều này cho thấy được mô hình ban đầu chọn đã được tối ưu và không cần laoij bỏ biến hay thêm biến khác vào.
Điều này cho thấy được, tất cả các biến trong mô hình đều có ý nghĩa thống kê tức là p value đều nhỏ hơn 0.05

## Mô hình Ridge Regression (Mô hình anyf giảm được sự đa cộng tuyến cao)
--> Giamr được phương sai, overfitting
--> Khi mà tính đa cộng tuyến cao -> mô hình này giúp ổn định hệ số hồi quy

### Chuẩn hóa dữ liệu 

```{r}
X_train <- model.matrix(LIFE.EXPECTANCY ~ INCOME.COMPOSITION.OF.RESOURCES + ADULT.MORTALITY + SCHOOLING + BMI, data = train_data)[,-1]
y_train <- train_data$LIFE.EXPECTANCY

X_test <- model.matrix(LIFE.EXPECTANCY ~ INCOME.COMPOSITION.OF.RESOURCES + ADULT.MORTALITY + SCHOOLING + BMI, data = test_data)[,-1]
y_test <- test_data$LIFE.EXPECTANCY

```
# Cải thiện mô hình
### Xây dựng mô hình Ridge Regression

```{r}
# Tìm giá trị lambda tối ưu bằng Cross-Validation
set.seed(123)
cv_ridge <- cv.glmnet(X_train, y_train, alpha = 0)

# Xây dựng mô hình Ridge với lambda tối ưu
ridge_model <- glmnet(X_train, y_train, alpha = 0, lambda = cv_ridge$lambda.min)

# Xem hệ số hồi quy
coef(ridge_model)

```


# KIỂM ĐỊNH GIẢ ĐỊNH HỒI QUY 

### Kiểm định phần dư

```{r}
par(mfrow = c(2, 2))
plot(final_model)
```

###  Kiểm tra phương sai đồng nhất
```{r}
bptest(final_model)
```
###  Kiểm tra tự tương quan (Durbin-Watson Test)
```{r}
durbinWatsonTest(final_model)
```

## Kiểm định mô hình Ridge Regression

```{r}
# 1. Tính phần dư và giá trị dự đoán
ridge_pred_train <- predict(ridge_model, s = cv_ridge$lambda.min, newx = X_train)
residuals_ridge <- y_train - ridge_pred_train

# 2. Kiểm tra phương sai đồng nhất
lm_resid <- lm(residuals_ridge ~ ridge_pred_train)
bptest(lm_resid)  # p > 0.05 → Đạt

# 3. Kiểm tra phân phối chuẩn
qqnorm(residuals_ridge)
qqline(residuals_ridge, col = "red")
shapiro.test(residuals_ridge)  

# 4. Kiểm tra tự tương quan
durbinWatsonTest(lm_resid)  
```

## Bảng hệ số
```{r}
broom::tidy(final_model) %>%
  mutate(
    p.value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3)),
    estimate = round(estimate, 2)
  )
```



# Đánh giá hiệu suất
Đánh giá 2 mô hình
>>> Trên tập train
>>> Trên tập test
Nói lên được RMSE, R-squared trên tập train và test


--> Đưa ra kết luận: mô hình nào tối ưu hơn và có cần tối ưu hóa mô hình đó nữa không, nếu có thì thêm tương tác biến, xử lí outliers lại -> Đưa ra mô hình và làm lại các bước trên để so sánh với mô hình cũ